# -*- coding: utf-8 -*-
"""Langsmith_Llamaindex_Ads.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yFHjvjAHR8LSWB9PSZaH_bJlAu_4VI92
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install llama-index-llms-openai llama-index-experimental

# Commented out IPython magic to ensure Python compatibility.
# %pip install llama-index-llms-openai
# !pip install llama-index
# ! pip install -U langsmith openai ollama

# Import Colab Secrets userdata module
from google.colab import userdata

# Set OpenAI API key
import os
os.environ["OPENAI_API_KEY"] = userdata.get('OPENAI_API_KEY')

from llama_index.core.query_pipeline import (
    QueryPipeline as QP,
    Link,
    InputComponent,
)
from llama_index.experimental.query_engine.pandas import (
    PandasInstructionParser,
)
from llama_index.llms.openai import OpenAI
from llama_index.core import PromptTemplate


import os
os.environ['LANGCHAIN_TRACING_V2'] = 'true' # enables tracing
os.environ["LANGCHAIN_API_KEY"] = "enter your api key"

import os
os.environ["LANGCHAIN_PROJECT"] = "User_logs"

import pandas as pd
df = pd.read_excel('/content/Processed_ads_2.xlsx')

from langsmith import traceable

class SQLQueryPipeline:
    def __init__(self, df, model="gpt-3.5-turbo"):
        # self.csv_path = csv_path
        self.df = df
        self.llm = OpenAI(model= model,temperature=0.0) # max-tokens 'gpt-4o'
        self.instruction_str = (
            "0. No need to use pd.to_datetime as 'Date' column is already in date_time format.\n"
            "1. Convert the query to executable Python code using Pandas.\n"
            "2. The Date column is already converted to Datetime Format using expression \n"
            "3. If asked about keywords, be careful because all keywords in Search keyword are not unique. \n"
            "4. If asked about `Brand Video` then fetch results for both `Brand Video` and `Brand Video Full` \n"

            "5. For the questions related to efficiency, effectiveness of ads or programs, consider all ther parmeters like `Reach`,`Impressions`,`Adds to cart`,`Unique link clicks`,`Amount Spent HYP 20` for Answering, if any specific parameter is not mentioned in question. \n"
            "6. Think about problem, break in steps \n"
            "7. Decide if you need to use groupby for questions \n"
                "example : <query>Which location have zero reach \n"
                "first find df.groupby('Location').agg({'Reach': 'sum'}) and then answer the question \n"
            "8. The final line of code should be a Python expression that can be called with the `eval()` function.\n"
            "9. The code should represent a solution to the query. \n"
            "10. PRINT ONLY THE EXPRESSION.\n"
            "11. Do not quote the expression.\n"
        )
        self.result = None

        self.pandas_prompt_str = (
            "You are working with a pandas dataframe in Python.\n"
            "The name of the dataframe is `df`.\n"
            "The dataframe has Thirteen columns: \n"
            "1. `LocationID`: A unique identifier for the location, e.g., '38QSR44'. \n"
            "2. `Location`: The name of the location, e.g., 'Austin'.\n"
            "3. `AdProgram`: The name of the advertising program, e.g., 'JINYA_Program_Interests'.\n"
            "4. `Ad_ID`: The unique identifier for the advertisement, e.g., 'IGDC4847'.  \n"
            "5. `Ad_description`: The description of the advertisement, e.g., 'Brand Video Full'.\n"
            "6. `Date`: The date and time when the data was recorded, formatted as YYYY-MM-DD, e.g., '2022-01-01'\n"
            "7. `Campaign_ID`: The unique identifier for the campaign, e.g., 'WBUI5873'.\n"
            "8. `Campaign Description`: The description of the campaign, e.g., 'JINYA Ramen Bar_Program'.\n"
            "9. `Reach`: The number of unique users who saw the ad, e.g., 147.\n"
            "10. `Impressions`: The total number of times the ad was displayed, e.g., 163.\n"
            "11. `Adds to cart`: The number of times the ad led to items being added to the cart, e.g., 2.\n"
            "12. `Unique link clicks`: The number of unique clicks on the ad's link, e.g., 6.\n"
            "13. `Amount Spent HYP 20`: The amount of money spent on the ad, e.g., 15.1625.\n"

            "This is the result of `print(df.head())`:\n"
            "{df_str}\n\n"
            "Follow these instructions:\n"
            "{instruction_str}\n"
            "Query: {query_str}\n\n"
            "Expression:"
        )

        self.response_synthesis_prompt_str = (
            "Given an input question, synthesize a response from the query results.\n"
            "Query: {query_str}\n\n"
            "Pandas Instructions: \n{pandas_instructions}\n\n"
            "Pandas Output: {pandas_output}\n\n"
            "Response: "
        )

        self.pandas_prompt = PromptTemplate(self.pandas_prompt_str).partial_format(
            instruction_str=self.instruction_str, df_str=self.df.head(5)
        )

        self.pandas_output_parser = PandasInstructionParser(self.df)
        self.response_synthesis_prompt = PromptTemplate(self.response_synthesis_prompt_str)

        self.qp = QP(
            modules={
                "input": InputComponent(),
                "pandas_prompt": self.pandas_prompt,
                "text2pandas_llm": self.llm,
                "pandas_output_parser": self.pandas_output_parser,
                "response_synthesis_prompt": self.response_synthesis_prompt,
                "response_synthesis_llm": self.llm,
            },
            verbose=True,
        )
        self.qp.add_chain(["input", "pandas_prompt", "text2pandas_llm", "pandas_output_parser"])
        self.qp.add_link("input", "response_synthesis_prompt", dest_key="query_str")
        self.qp.add_link("text2pandas_llm", "response_synthesis_prompt", dest_key="pandas_instructions")
        self.qp.add_link("pandas_output_parser","response_synthesis_prompt",dest_key="pandas_output")
        self.qp.add_link("response_synthesis_prompt", "response_synthesis_llm")


    def query_response(self, question):

        response, self.result = self.qp.run_with_intermediates(
        query_str= question, )

        #Function call to Pandas_Prompt
        self.Pandas_Prompt(self.result['pandas_prompt'].inputs)

        #Function call to Text2pandas LLM
        Text2Pandas_input = [
            {"role": "system", "content": "Generate Pandas Query"},
            {"role": "user", "content": self.result['text2pandas_llm'].inputs['messages']},
        ]
        self.Text2Pandas(Text2Pandas_input)

        #Function call to Pandas_Output_Parser
        self.Pandas_Output_Parser(self.result['pandas_output_parser'].inputs['input'].message.content)


        #Function call to Response_Synthesis_Prompt
        Response_llm_input = [
            {"role": "system", "content": "Given an input question, synthesize a response from the query results."},
            {"role": "user", "content": self.result['response_synthesis_llm'].inputs['messages']},
        ]
        self.Response_llm(Response_llm_input)

        return  self.result,response.message.content


    @traceable
    def Pandas_Prompt(self, ip):
        return self.result['pandas_prompt'].outputs

    @traceable(
        run_type="llm",
        metadata={"ls_provider": "openai", "ls_model_name": "gpt-4o"}
      )
    def Text2Pandas(self, messages : list):
        input_tokens = self.result['text2pandas_llm'].outputs['output'].raw.usage.prompt_tokens
        output_tokens = self.result['text2pandas_llm'].outputs['output'].raw.usage.completion_tokens
        return {
                "choices": [
                    {
                        "message": {
                            "role": "assistant",
                            "content": self.result['text2pandas_llm'].outputs['output'].message.content
                        }
                    }
                ],
                "usage_metadata": {
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "total_tokens": input_tokens+output_tokens,
                },
            }



    @traceable
    def Pandas_Output_Parser(self,ip):
        return self.result['pandas_output_parser'].outputs



    @traceable(
        run_type="llm",
        metadata={"ls_provider": "openai", "ls_model_name": "gpt-4o"}
      )
    def Response_llm(self,messages : list ):
        input_tokens = self.result['response_synthesis_llm'].outputs['output'].raw.usage.prompt_tokens
        output_tokens = self.result['response_synthesis_llm'].outputs['output'].raw.usage.completion_tokens
        return {
                "choices": [
                    {
                        "message": {
                            "role": "assistant",
                            "content": self.result['response_synthesis_llm'].outputs['output'].message.content
                        }
                    }
                ],
                "usage_metadata": {
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "total_tokens": input_tokens+output_tokens,
                },
            }

Pipe = SQLQueryPipeline(df)

# result, response = Pipe.query_response("How many impressions did our ads get in Austin?")

# result['text2pandas_llm'].outputs['output'].raw.usage.completion_tokens

@traceable
def run_llama(ques):

    result, response = Pipe.query_response(ques)
    input_tokens = result['text2pandas_llm'].outputs['output'].raw.usage.total_tokens
    output_tokens = result['response_synthesis_llm'].outputs['output'].raw.usage.total_tokens

    return response


run_llama("How many impressions did our ads get in Austin?")




